{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc96a05c",
   "metadata": {},
   "source": [
    "# Saving and re-using Plans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc74ba1",
   "metadata": {},
   "source": [
    "1. restate the query: I wanted to do this.....\n",
    "2. restate the plan that was created by LLM: this is the plan that you previously created ....\n",
    "3. Restate what you initially had in your mind: last time this plan didn't completely work because what I really wanted is....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7bf83",
   "metadata": {},
   "source": [
    "# Editing Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2607d9a",
   "metadata": {},
   "source": [
    "- Try to do the thinking stuff \"MANUALLY\" and not python with the command \"do it manually\". That way, it can do well on cognitive tasks\n",
    "- Sometimes LLMs keep repeating the same mistake because it might be fixed on one pattern. In that case you write \"try again\" and observe the output once more. when it starts producing the same mistake again, stop it as early as possible and edit after \"try again\" with \"try again on step 2\" to explicitly fix the issue in answer generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2eba01",
   "metadata": {},
   "source": [
    "# Checking Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964b23f",
   "metadata": {},
   "source": [
    "- Always fact check for hallucination. whenever the query is short and the answer is long, there should be more hallucination than when there is long query and short answer\n",
    "- Based on my question, identify the quotations that support the claim ..... in the pdf/content\n",
    "- create synthetic test cases (generate a sample data) and verify if it validates the test cases of learnined materials/tasks\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee5bb1a",
   "metadata": {},
   "source": [
    "# Breaking Down Bigger Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4325b5",
   "metadata": {},
   "source": [
    "- break the document into individual pieces that can be incrementally processed\n",
    "- eg: break the document into multiple 400 word files. then open each page and manually summarize what is on EACH PAGE... (after each 10 slide ask me if i want to proceed, if i say yes, you will keep on doing .. for the next 10..)\n",
    "- Keep it going: It might stop at some point. tell it to continue with \"PROCEED or CONTINUE\"\n",
    "- Build index/keyword mapping: analyze each page and build a master index along with page number based on ...\n",
    "- Using the index: Using your index, read the document ... .. and tell me if i ....\n",
    "- Break down task commands: analyze each section and show me the summarized section for each ... and also produce individual prompts for each section how ....... and show it to me...\n",
    "- If you focus on a specific section, LLM might get lost of the big picture context. In that case, Build outline first. (example: create an outline for .. based on ... ). Make sure to save the outline to a file incrementally along the steps. because at some time, LLM will forget the task at hand, and you will need to feed the LLM the outline file to continue controlling the big picture output. The more individual and independent you can break down the contents, the better the result. At the end, you can combine them together to put them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de8e1b",
   "metadata": {},
   "source": [
    "# 10 Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15548c18",
   "metadata": {},
   "source": [
    "1. Saving Intermediate Files in zip to prevent loss of progress\n",
    "2. Always Plan Step-by-Step and Save these plans for future reference o\n",
    "3. Use Mementos to have reminders of the state of the ongoing process by creating files listing the entire plan, the current step, and summarizing what has or hasn't been done. \n",
    "4. Always Have LLM Read and Explain Documents/Data to synchronize your understanding with GPT-4's understanding. Ask it to explain what it reads in several ways and test its understanding by having it generate examples\n",
    "5. Use Error Detection Methods to ensure consistency and accuracy. Employ references to specific identifiers or quotations to ensure that the output is supported by the documents you provided. \n",
    "6. Ask to Try Alternate Approaches to overcome failure and make continuous progress. \n",
    "7. Think of Prompts as Constraints for targeted and desired outputs.  Be explicit about your goals, requirements, and constraints.\n",
    "8. Edit the Conversation When Errors Occur to avoid error propagation. Edit and correct any chat message that produces a bad output immediately and regenerate the output. \n",
    "9. Get Key Information into the Conversation to enhance reasoning and understanding.  \n",
    "10. Tell to Analyze Without Python When Needed because not all tasks require code and rather need cognitive assistance. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
